summary ( sPID )
levels ( sPID ) <- c(" Democrat "," Democrat "," Independent ",
" Independent ", " Independent "," Republican "," Republican ")
summary ( sPID )
inca <- c (1.5 ,4 ,6 ,8 ,9.5 ,10.5 ,11.5 ,12.5 ,13.5 ,14.5 ,16 ,18.5 ,
21 ,23.5 ,27.5 ,32.5 ,37.5 ,42.5 ,47.5 ,55 ,67.5 ,82.5 ,97.5 ,115)
nincome <- inca [ unclass ( nes96 $ income )]
summary ( nincome )
barplot ( table ( nes96 $ educ ),col=" chocolate1 ")
matplot ( prop . table ( table ( nes96 $educ , sPID ),1), type ="l",
matplot(prop.table(table(nes96$educ,sPID),1), type ="l",
xlab =" Education",ylab ="Proportion",lty=c(1 ,2 ,5))
mmodi <- step ( mmod )
mmod <- multinom ( sPID ~ age + educ + nincome , nes96 )
mmod <- multinom(sPID~age + educ + nincome , nes96 )
library ( nnet )
mmod <- multinom(sPID~age + educ + nincome , nes96 )
mmodi <- step ( mmod )
predict (mmodi , data . frame ( nincome =il), type =" probs ")
predict(mmodi,data.frame(nincome =il), type ="probs")
nincome=il
schulen <- read.csv2("http://schulen.bildung-rp.de/fileadmin/zykLus/schuldaten_export.csv")
schulen
head(schulen)
link<- "http://www.statistik.at/web_de/static/mz_2013_sds_-_datensatz_080469.sav"
MZ13 <- read.spss(file=link,
to.data.frame=TRUE,
use.value.labels=FALSE)
library(foreign)
link<- "http://www.statistik.at/web_de/static/mz_2013_sds_-_datensatz_080469.sav"
MZ13 <- read.spss(file=link,
to.data.frame=TRUE,
use.value.labels=FALSE)
MZ13
head(MZ13)
attr(MZ13)
attributes(MZ13)
ab <- attributes(MZ13)
ab$variable.labels
link<- "http://www.statistik.at/web_de/static/mz_2013_sds_-_datensatz_080469.sav"
MZ13 <- read.spss(file=link,
to.data.frame=TRUE,
use.value.labels=T)
attribute(MZ13)
attributes(MZ13)
ab <- attributes(MZ13)
head(ab)
link<- "http://www.statistik.at/web_de/static/mz_2013_sds_-_datensatz_080469.sav"
levels(ab)
levels(MZ13[,2])
labels(MZ13[,2])
MZ13[,2]
labels(MZ13[,2])
labels(MZ13[,1])
labels(MZ13[,4])
labels(MZ13[,5])
?polr
pomodi <- step ( pomod )
pomod <- polr ( sPID ~ age + educ + nincome , nes96 )
pomodi <- step ( pomod )
data(orings)
splom(gala [,c(1 ,2 ,3 ,4)])
library(faraway)
data(orings)
plot ( damage /6 ~ temp , orings , xlim =c(0 ,100) , ylim =c(0 ,1) ,
xlab =" temperature", ylab ="accident")
lmod <- lm( damage /6 ~ temp , orings )
abline (lmod , col =4); abline (h =0); abline (h=1)
plot ( damage /6 ~ temp , orings , xlim =c(0 ,100) , ylim =c(0 ,1) ,
xlab =" temperature", ylab ="accident")
abline (lmod , col =4); abline (h =0); abline (h=1)
data ( gala )
gala <-gala [,-2]
gala $ Species <- round ( sqrt ( gala $ Species ))
head ( gala )
library ( solaR )
splom(gala [,c(1 ,2 ,3 ,4)])
x <-seq (0,1, by =.001)
plot ( binomial ()$ linkfun (x),x, xlab =" Logit (p)"
,ylab ="p",type ="l")
plot(binomial ( link ="probit")$ linkfun (x),x, xlab ="Probit(p)"
,ylab ="p",type ="l")
abline (h=c(0 ,1))
abline (h=0.5 , col=" blue ")
abline (v=0, col=" blue ")
summary (glm(am ~ hp + wt , data =mtcars , family = binomial ) )
library ( MASS )
example ( birthwt )
head (bwt)
summary (bwt)
library ( nnet )
multinom ( formula = low ~ ., data = bwt)
data(nes96)
head(nes96 [,c(1:7)])
data ( nes96 )
sPID <- nes96 $PID
summary ( sPID )
levels ( sPID ) <- c(" Democrat "," Democrat "," Independent ",
" Independent ", " Independent "," Republican "," Republican ")
summary ( sPID )
inca <- c (1.5 ,4 ,6 ,8 ,9.5 ,10.5 ,11.5 ,12.5 ,13.5 ,14.5 ,16 ,18.5 ,
21 ,23.5 ,27.5 ,32.5 ,37.5 ,42.5 ,47.5 ,55 ,67.5 ,82.5 ,97.5 ,115)
nincome <- inca [ unclass ( nes96 $ income )]
summary ( nincome )
barplot ( table ( nes96 $ educ ),col=" chocolate1 ")
matplot(prop.table(table(nes96$educ,sPID),1), type ="l",
xlab =" Education",ylab ="Proportion",lty=c(1 ,2 ,5))
library ( nnet )
mmod <- multinom(sPID~age + educ + nincome , nes96 )
mmodi <- step ( mmod )
library ( MASS )
pomod <- polr ( sPID ~ age + educ + nincome , nes96 )
c( deviance ( pomod ), pomod $edf)
pomodi <- step ( pomod )
data(orings)
library(faraway)
data(orings)
plot ( damage /6 ~ temp , orings , xlim =c(0 ,100) , ylim =c(0 ,1) ,
xlab =" temperature", ylab ="accident")
lmod <- lm( damage /6 ~ temp , orings )
abline (lmod , col =4); abline (h =0); abline (h=1)
plot ( damage /6 ~ temp , orings , xlim =c(0 ,100) , ylim =c(0 ,1) ,
xlab =" temperature", ylab ="accident")
abline (lmod , col =4); abline (h =0); abline (h=1)
library(faraway)
data(orings)
plot ( damage /6 ~ temp , orings , xlim =c(0 ,100) , ylim =c(0 ,1) ,
xlab =" temperature", ylab ="accident")
lmod <- lm( damage /6 ~ temp , orings )
abline (lmod , col =4); abline (h =0); abline (h=1)
lmod <- lm( damage /6 ~ temp , orings )
data(nes96)
?nes96
library(faraway)
data(nes96)
head(nes96 [,c(1:7)])
rm(nes96)
data(nes96)
date()
doc4=  xmlParse("http://www.r-project.org/mail.html",isHTML=TRUE)
library(XML)
doc4=  xmlParse("http://www.r-project.org/mail.html",isHTML=TRUE)
ab <- readHTMLList(link)
link <- "https://de.wikipedia.org/wiki/Landkreis_Ahrweiler"
ab <- readHTMLList(link)
ab
ab <- xmlParse(link)
zz<-url(link,'r',blocking=F)
a<-readLines(zz)
close(zz)
a
length(a)
info <- agrep("Kottenborn",a)
info
info612 <- a[[612]]
info612
path <- "J:/Work/Statistik/Kolb/Beratung/Stichprobendesign/EnAhrgie"
rm(list=ls())
gc()
path <- "J:/Work/Statistik/Kolb/Beratung/Stichprobendesign/EnAhrgie"
library(maps)
mapStates = map("state", fill = TRUE, plot = FALSE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
library(magrittr)
mapStates = map("state", fill = TRUE, plot = FALSE)
leaflet(data = mapStates) %>% addTiles() %>%
addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)
colorRamps
install.packages("colorRamps")
geocode("Mannheim")
library(ggmap)
geocode("Mannheim")
install.packages("maptools")
library(ggmap)
coords <- geocode("GESIS Mannheim")
library(geosmdata2)
coords <- geocode_osm("GESIS Mannheim")
coords
library(magrittr)
library(leaflet)
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=coords$lon, lat=coords$lat, popup="GESIS Mannheim")
coords$lat
coords
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng=coords[2], lat=coords[1], popup="GESIS Mannheim")
m  # Print the map
geocode("Mannheim Wasserturm")
geocode("Mannheim")
library(tmap)
data(Europe)
qtm(Europe)
head(Europe)
datatable(Europe)
library(DT)
datatable(Europe)
Europe
Europe@data
datatable(Europe@data)
kable(Europe@data[1:8,1:5])
qtm(Europe, fill="gdp_cap_est")
qtm(Europe, fill="gdp_cap_est", text="iso_a3")
geocode("Mannheim")
geocode("Mannheim",source="google")
?geocode
date()
library(ggmap)
geocode
?geocode
geocode("Mannheim Wasserturm",source="google")
qmap(location = 'Mannheim', zoom = 14,
maptype="toner",source="stamen") + geom_point(aes(x = lon, y = lat),
data = ListPOI)
ListPOI <-rbind(POI1,POI2,POI3)
POI1 <- geocode("B2, 1 Mannheim",source="google")
POI1
POI2 <- geocode("Hbf Mannheim",source="google")
POI2
POI3 <- geocode("Wasserturm Mannheim",source="google")
ListPOI <-rbind(POI1,POI2,POI3)
ListPOI
qmap(location = 'Mannheim', zoom = 14,
maptype="toner",source="stamen") + geom_point(aes(x = lon, y = lat),
data = ListPOI)
MA_map <- qmap(location = 'Mannheim', zoom = 14,
maptype="toner",source="stamen")
MA_map +
geom_point(aes(x = lon, y = lat),
data = ListPOI)
dev.off()
MA_map +
geom_point(aes(x = lon, y = lat),
data = ListPOI)
MA_map +
geom_point(aes(x = lon, y = lat),col="red",
data = ListPOI)
d <- SPARQL(url="http://services.data.gov.uk/reference/sparql",
query="SELECT * WHERE { ?s ?p ?o . } LIMIT 10",
ns=c('time','<http://www.w3.org/2006/time#>'))
library(SPARQL)
endpoint = "http://foaf.tv/hypoid/sparql.php"
q = "PREFIX vcard: <http://www.w3.org/2006/vcard/ns#>\nPREFIX foaf:\n<http://xmlns.com/foaf/0.1/>\nPREFIX rv:\n<http://www.wifo-ravensburg.de/rdf/semanticweb.rdf#>\nPREFIX gr:\n<http://purl.org/goodrelations/v1#>\n \nSELECT ?poi ?l ?lon ?lat ?k\nWHERE {\nGRAPH <http://www.heppresearch.com/dev/dump.rdf> {\n?poi\nvcard:geo ?l .\n  ?l vcard:longitude ?lon .\n  ?l vcard:latitude ?lat\n.\n ?poi foaf:homepage ?hp .\n?poi rv:kategorie ?k .\n\n}\n}\n"
res<-SPARQL(endpoint,q)
d <- SPARQL(url="http://services.data.gov.uk/reference/sparql",
query="SELECT * WHERE { ?s ?p ?o . } LIMIT 10",
ns=c('time','<http://www.w3.org/2006/time#>'))
is.data.frame(d$results)
endpoint <- "http://semanticweb.cs.vu.nl/lop/sparql/"
q <-
"SELECT *
WHERE {
?event sem:hasPlace ?place .
?place eez:inPiracyRegion ?region .
}"
prefix <- c("lop","http://semanticweb.cs.vu.nl/poseidon/ns/instances/",
"eez","http://semanticweb.cs.vu.nl/poseidon/ns/eez/")
res <- SPARQL(endpoint,q,prefix)$results
res
endpoint = "http://foaf.tv/hypoid/sparql.php"
q = "PREFIX vcard: <http://www.w3.org/2006/vcard/ns#>\nPREFIX foaf:\n<http://xmlns.com/foaf/0.1/>\nPREFIX rv:\n<http://www.wifo-ravensburg.de/rdf/semanticweb.rdf#>\nPREFIX gr:\n<http://purl.org/goodrelations/v1#>\n \nSELECT ?poi ?l ?lon ?lat ?k\nWHERE {\nGRAPH <http://www.heppresearch.com/dev/dump.rdf> {\n?poi\nvcard:geo ?l .\n  ?l vcard:longitude ?lon .\n  ?l vcard:latitude ?lat\n.\n ?poi foaf:homepage ?hp .\n?poi rv:kategorie ?k .\n\n}\n}\n"
res<-SPARQL(endpoint,q)
q <-
"SELECT *
WHERE {
?event sem:eventType ?event_type .
?event sem:hasPlace ?place .
?place eez:inPiracyRegion ?region .
}"
res <- SPARQL(endpoint,q,ns=prefix)$results
restable <- table(res$event_type,res$region)
par(mar=c(4,10,1,1))
barplot(restable,col=rainbow(10),horiz=TRUE,las=1,cex.names=0.8)
legend("topright",rownames(restable),
cex=0.8,bty="n",fill=rainbow(10))
endpoint <- "http://live.dbpedia.org/sparql"
options <- NULL
prefix <- c("db","http://dbpedia.org/resource/")
sparql_prefix <- "PREFIX dbp: <http://dbpedia.org/property/>
PREFIX dc: <http://purl.org/dc/terms/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
"
q <- paste(sparql_prefix,
'SELECT ?actor ?movie ?director ?movie_date
WHERE {
?m dc:subject <http://dbpedia.org/resource/Category:American_films> .
?m rdfs:label ?movie .
FILTER(LANG(?movie) = "en")
?m dbp:released ?movie_date .
FILTER(DATATYPE(?movie_date) = xsd:date)
?m dbp:starring ?a .
?a rdfs:label ?actor .
FILTER(LANG(?actor) = "en")
?m dbp:director ?d .
?d rdfs:label ?director .
FILTER(LANG(?director) = "en")
}')
res <- SPARQL(endpoint,q,ns=prefix,extra=options)$results
res
q <- "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX atlas: <http://rdf.ebi.ac.uk/resource/atlas/>
PREFIX atlasterms: <http://rdf.ebi.ac.uk/terms/atlas/>
SELECT DISTINCT ?genename ?factorLabel ?tStat WHERE {
atlas:E-GEOD-8527 atlasterms:hasAnalysis ?analysis .
?analysis atlasterms:hasExpressionValue ?value .
?value atlasterms:pValue ?pvalue .
?value atlasterms:tStatistic ?tStat .
?value atlasterms:hasFactorValue ?factor .
?factor atlasterms:propertyValue ?factorLabel .
?value atlasterms:isMeasurementOf ?probe .
?probe atlasterms:dbXref ?dbXref .
?dbXref rdfs:label ?genename .
} ORDER BY ?genename limit 10000"
d <- SPARQL(url="http://www.ebi.ac.uk/rdf/services/atlas/sparql",
query=q)
d
head(d)
faithful
load("J:/Work/Statistik/Kolb/Paper/ZensusAsta1/data/ZensusImp_Asta_3Hfk.RData")
(load("J:/Work/Statistik/Kolb/Paper/ZensusAsta1/data/ZensusImp_Asta_3Hfk.RData"))
Daterg
library(xtable)
xtable(Daterg)
Daterg
Daterg2 <- unlist(Daterg)
Daterg2
Daterg[[1]]
names(Daterg)
SamplingPoints <- names(Daterg)
Daterg
Dat <- data.frame(SamplingPoints=names(Daterg))
Dat
do.call(rbind,Daterg)
do.call(rbind,round(Daterg,digits=3))
Dat <- do.call(rbind,Daterg)
Dat <- round(Dat,digits=3)
Dat
Dat <- Dat[c(3,1,2),]
Dat
rownames(Dat) <- c("SMP A","SMP B","SMP C")
Dat
xtable(Dat)
date()
date()
library(rggobi)
install.packages("rggobi")
library(rggobi)
install.packages("iplots",dep=TRUE)
library(iplots)
cyl.f <- factor(mtcars$cyl)
gear.f <- factor(mtcars$factor)
attach(mtcars)
ihist(mpg) # histogram
ibar(carb) # barchart
ipcp(mtcars[c("mpg","wt","hp")]) # parallel coordinates
imosaic(cyl.f,gear.f) # mosaic plot
plot(SAL,col="blue")
library(sp)
library("raster")
DEU4 <- getData('GADM', country='DEU', level=4)
head(DEU4@data)
SAL <- DEU4[DEU4@data$ID_1==12,]
plot(SAL)
plot(SAL,col="blue")
library(sp)
SAL$Zufall <- runif(length(SAL))
spplot(SAL,"Zufall")
library(stargazer)
install.packages("stargazer")
library(stargazer)
stargazer(attitude)
library(knitr)
library(knitr)
kable(head(iris), format = "latex")
date()
require("RPostgreSQL")
install.packages("RPostgreSQL")
require("RPostgreSQL")
pw <- {
"new_user_password"
}
drv <- dbDriver("PostgreSQL")
con <- dbConnect(drv, dbname = "postgres",
host = "localhost", port = 5432,
user = "openpg", password = pw)
pw <- {
"PAsswort82"
}
drv <- dbDriver("PostgreSQL")
con <- dbConnect(drv, dbname = "cartable",
host = "localhost", port = 5432,
user = "postgres", password = pw)
dbExistsTable(con, "cartable")
dbExistsTable(con, "tab1")
data(mtcars)
df <- data.frame(carname = rownames(mtcars),
mtcars,
row.names = NULL)
df$carname <- as.character(df$carname)
rm(mtcars)
dbWriteTable(con, "tab1",
value = df, append = TRUE, row.names = FALSE)
generator <- read.csv("https://raw.githubusercontent.com/Japhilko/GeoData/master/data/Deutschland_generator.csv")
head(generator)
colnames(generator)
str(X)
attach(generator)
str(X)
df <- data.frame(generator,
row.names = NULL)
dbWriteTable(con, "tab1",
value = df, append = TRUE, row.names = FALSE)
install.packages("pollstR")
gesis_gc <- geocode("Gesis Mannheim")
library(ggmap)
gesis_gc <- geocode("Gesis Mannheim")
library(raster)
projection(gesis_gc)
gesis_gc
install.packages("rmongodb")
library(rmongodb)
install.packages("visNetwork")
library(visNetwork)
sex <- c("m","w","m")
location <- c("Mannheim","Mannheim","Stuttgart")
HHdat <- data.frame(sex,location)
HHagg <- with(HHdat,data.frame(table(sex,location)))
HHdat <- data.frame(sex,location)
HHagg <- with(HHdat,data.frame(table(sex,location)))
HHagg
devtools::install_github("Stan125/GREA")
url <- "http://www.berlin.de/sehenswuerdigkeiten/"
library(xml2)
isite <- read.html(url)
library(xml2)
url <- "http://www.berlin.de/sehenswuerdigkeiten/"
isite <- read.html(url)
isite <- read_html(url)
head(isite)
isite
library(tm)
install.packages("tm")
library(tm)
library(stringi)
library(proxy)
install.packages("proxy")
wiki <- "http://en.wikipedia.org/wiki/"
titles <- c("Berlin", "Riemann_integral", "Riemann-Stieltjes_integral", "Derivative",
"Limit_of_a_sequence", "Edvard_Munch", "Vincent_van_Gogh", "Jan_Matejko",
"Lev_Tolstoj", "Franz_Kafka", "J._R._R._Tolkien")
articles <- character(length(titles))
i<-1
stri_paste(wiki, titles[i])
titles <- c("Berlin", "Köln", "Frankfurt_am_Main")
articles <- character(length(titles))
articles[i] <- stri_flatten(readLines(stri_paste(wiki, titles[i])), col = " ")
articles[i]
docs <- Corpus(VectorSource(articles))
docs
docs[[1]]
docs2 <- tm_map(docs, function(x) stri_replace_all_regex(x, "<.+?>", " "))
docs3 <- tm_map(docs2, function(x) stri_replace_all_fixed(x, "\t", " "))
docs4 <- tm_map(docs3, PlainTextDocument)
docs5 <- tm_map(docs4, stripWhitespace)
docs6 <- tm_map(docs5, removeWords, stopwords("english"))
docs7 <- tm_map(docs6, removePunctuation)
docs8 <- tm_map(docs7, tolower)
docs8[[1]]
docsTDM <- TermDocumentMatrix(docs8)
docsTDM <- TermDocumentMatrix(docs8)
library(XML)
tab <- readHTMLTable("http://www.top10berlin.de/de/cat/freizeit-268/sehenswuerdigkeiten-der-superlative-326")
tab
lists <- readHTMLList("https://de.wikipedia.org/wiki/Liste_von_Sehensw%C3%BCrdigkeiten_in_Berlin")
lists
library(geosmdata)
osmnodes <- get_osm_nodes("tourism=attraction","Berlin")
osmnodes
objii <- "attraction"
placei <- "Berlin"
osmnodes <- get_osm_nodes(obji,placei)
obji <- "tourism=attraction"
objii <- "attraction"
placei <- "Berlin"
getwd()
setwd("C:/Users/kolbjp/Documents/GitHub/DataAnalysis/PredictiveAnalytics/slides")
write_xml(osmnodes,file=paste0("data/",objii,"_",placei,".xml"))
saveXML(osmnodes,file=paste0("data/",objii,"_",placei,".xml"))
info <- extract_osm_nodes(osmnodes,objii)
info
library("osmar")
src <- osmsource_api()
placei <- "Sippersfeld, Haupstraße 50"
gc <- geocode(placei)
library("ggmap")
gc <- geocode(placei)
placei <- "Sippersfeld, Haupstrasse 50"
gc <- geocode(placei)
gc
bb <- center_bbox(gc$lon, gc$lat, 1000, 1000)
placeii <- "Sippersfeld_Hpstr"
placeii <- "Sippersfeld_Hpstr50"
bb <- center_bbox(gc$lon, gc$lat, 1000, 1000)
ua <- get_osm(bb, source = src)
ua
map1 <- qmap(placei,maptype="sattelite")
map1 <- qmap(placei,maptype="satellite",zoom=18)
map1
7+8
