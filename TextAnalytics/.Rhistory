library(tm)
library(stringi)
library(proxy)
install.packages("proxy")
library(proxy)
wiki <- "http://en.wikipedia.org/wiki/"
articles <- character(length(titles))
titles <- c("Zika-Virus", "Influenza-A-Virus_H1N1", "Spanische_Grippe", "Influenzavirus",
"Vogelgrippe_H5N1", "Legionellose-Ausbruch_in_Warstein_2013", "Legionellose-Ausbruch_in_Jülich_2014")
articles <- character(length(titles))
for (i in 1:length(titles)) {
articles[i] <- stri_flatten(readLines(stri_paste(wiki, titles[i])), col = " ")
}
i
stri_paste(wiki, titles[i])), col = " ")
stri_paste(wiki, titles[i])
wiki <- "http://de.wikipedia.org/wiki/"
titles <- c("Zika-Virus", "Influenza-A-Virus_H1N1", "Spanische_Grippe", "Influenzavirus",
"Vogelgrippe_H5N1", "Legionellose-Ausbruch_in_Warstein_2013", "Legionellose-Ausbruch_in_Jülich_2014")
articles <- character(length(titles))
for (i in 1:length(titles)) {
articles[i] <- stri_flatten(readLines(stri_paste(wiki, titles[i])), col = " ")
}
docs <- Corpus(VectorSource(articles))
docs2 <- tm_map(docs, function(x) stri_replace_all_regex(x, "<.+?>", " "))
docs3 <- tm_map(docs2, function(x) stri_replace_all_fixed(x, "\t", " "))
docs4 <- tm_map(docs3, PlainTextDocument)
docs5 <- tm_map(docs4, stripWhitespace)
docs6 <- tm_map(docs5, removeWords, stopwords("english"))
docs7 <- tm_map(docs6, removePunctuation)
docs8 <- tm_map(docs7, tolower)
length(docs8)
getwd()
setwd("TextAnalytics/")
save(docs8,file="data/Krankheiten_wiki.Rdata")
load("data/Krankheiten_wiki.Rdata")
docsTDM <- TermDocumentMatrix(docs8)
docsTDM <- TermDocumentMatrix(docs8)
docs8 <- tm_map(docs7, tolower)
docsTDM <- TermDocumentMatrix(docs8)
?TermDocumentMatrix
data("crude")
typeof(crude)
typeof(crude[[1]])
typeof(docs8)
docsTDM <- TermDocumentMatrix(docs8[[1]])
docsTDM <- TermDocumentMatrix(docs8)
crude
docs8
docs2
docs
articles
library(tm)
library(stringi)
library(proxy)
wiki <- "http://en.wikipedia.org/wiki/"
titles <- c("Integral", "Riemann_integral", "Riemann-Stieltjes_integral", "Derivative",
"Limit_of_a_sequence", "Edvard_Munch", "Vincent_van_Gogh", "Jan_Matejko",
"Lev_Tolstoj", "Franz_Kafka", "J._R._R._Tolkien")
articles <- character(length(titles))
for (i in 1:length(titles)) {
articles[i] <- stri_flatten(readLines(stri_paste(wiki, titles[i])), col = " ")
}
docs <- Corpus(VectorSource(articles))
docs <- Corpus(VectorSource(articles))
docs2 <- tm_map(docs, function(x) stri_replace_all_regex(x, "<.+?>", " "))
docs3 <- tm_map(docs2, function(x) stri_replace_all_fixed(x, "\t", " "))
docs4 <- tm_map(docs3, PlainTextDocument)
docs5 <- tm_map(docs4, stripWhitespace)
docs6 <- tm_map(docs5, removeWords, stopwords("english"))
docs7 <- tm_map(docs6, removePunctuation)
docs8 <- tm_map(docs7, tolower)
docsTDM <- TermDocumentMatrix(docs8)
docs8
docsdissim <- dissimilarity(docsTDM, method = "cosine")
library(tm)
library(stringi)
library(proxy)
docsTDM <- TermDocumentMatrix(docs8)
docsdissim <- dissimilarity(docsTDM, method = "cosine")
library(arules)
install.packages("arules")
library(arules)
docsTDM <- TermDocumentMatrix(docs8)
docsdissim <- dissimilarity(docsTDM, method = "cosine")
docs8 <- tm_map(docs8, PlainTextDocument)
docsTDM <- TermDocumentMatrix(docs8)
docsdissim <- dissimilarity(docsTDM, method = "cosine")
docsdissim <- tm::dissimilarity(docsTDM, method = "cosine")
docsdissim <- tm:::dissimilarity(docsTDM, method = "cosine")
docsdissim <- tm::dissimilarity(docsTDM, method = "cosine")
detach("package:arules", unload=TRUE)
docsdissim <- dissimilarity(docsTDM, method = "cosine")
library("tm", lib.loc="~/R/win-library/3.3")
docsdissim <- dissimilarity(docsTDM, method = "cosine")
docsdissim <- dissimilarity(docsTDM, method = "cosine")
docsdissim <- tm::dissimilarity(docsTDM, method = "cosine")
docsdissim <- tm:::dissimilarity(docsTDM, method = "cosine")
docsdissim <- proxy::dist(docsTDM, method = "cosine")
docsdissim <- proxy::dist(docsTDM)
?proxy::dist
start   = "http://www.iens.nl/restaurant/?q=&amp;amp;perPagina=20&amp;amp;pagina="
httploc = paste(start,i,sep="")
restaurants     = html(httploc)
recensieinfo    = html_text(html_nodes(restaurants,xpath='//div[@class="listerItem_score"]'))
restaurantLabel = html_nodes(restaurants,".listerItem")
restName        = html_text(html_nodes(reslabel2,".fontSerif"))
restAddress     = html_nodes(restarantLabel ,"div address")
Nreviews        = str_extract(str_extract(recensieinfo,pattern="[0-9]* recensies"), pattern = "[0-9]*")
averageScore    = str_extract(recensieinfo,pattern="[0-9].[0-9]")
# more statements
Needed <- c("tm", "SnowballCC", "RColorBrewer", "ggplot2", "wordcloud", "biclust", "cluster", "igraph", "fpc")
install.packages(Needed, dependencies=TRUE)
Needed <- c("tm", "SnowballCC", "RColorBrewer", "ggplot2", "wordcloud", "biclust", "cluster", "igraph", "fpc")
install.packages(Needed, dependencies=TRUE)
install.packages(Needed, dependencies = TRUE)
library(tm)
library(stringi)
library(proxy)
load("data/Krankheiten_wiki.Rdata")
(load("data/Krankheiten_wiki.Rdata"))
summary(docs8)
summary(Corpus(docs8))
summary(docs8)
docs8
docs <- tm_map(docs8, removePunctuation)
docs
inspect(docs8[3])
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("german"))
docs
inspect(docs8[3])
docs <- tm_map(docs, removeWords, c("document", "element"))
docs
inspect(docs8[3])
library(SnowballC)
docs <- tm_map(docs, stemDocument)
docs <- TermDocumentMatrix(docs)
docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
dtm
tdm <- TermDocumentMatrix(docs)
freq <- colSums(as.matrix(dtm))
length(freq)
dtms <- removeSparseTerms(dtm, 0.1)
inspect(dtms)
freq[head(ord)]
head(table(freq), 20)
freq <- colSums(as.matrix(dtms))
freq
library(ggplot2)
p <- ggplot(subset(wf, freq>50), aes(word, freq))
wf <- data.frame(word=names(freq), freq=freq)
library(ggplot2)
p <- ggplot(subset(wf, freq>50), aes(word, freq))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
freq <- colSums(as.matrix(dtms[1]))
freq <- colSums(as.matrix(dtms[[1]))
dtm <- DocumentTermMatrix(docs[1])
dtm
dtm2 <- DocumentTermMatrix(docs[2])
tdm2 <- TermDocumentMatrix(docs[2])
dtm1 <- DocumentTermMatrix(docs[1])
tdm1 <- TermDocumentMatrix(docs[1])
freq1 <- colSums(as.matrix(dtm1))
dtms1 <- removeSparseTerms(dtm1, 0.1)
dtms1 <- removeSparseTerms(dtm1, 0.1)
freq1 <- colSums(as.matrix(dtms1))
wf1 <- data.frame(word=names(freq1), freq=freq1)
p <- ggplot(subset(wf1, freq1>50), aes(word1, freq1))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
p <- ggplot(subset(wf1, freq1>50), aes(word, freq1))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
p <- ggplot(subset(wf1, freq1>50), aes(word, freq))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
install.packages("devtools")
require(devtools)
install_url("http://www.omegahat.org/Rstem/Rstem_0.4-1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz")
library("plyr")
library("ggplot2")
library("wordcloud")
library("RColorBrewer")
library("tm")
library("SnowballC")
data <- readLines("https://www.r-bloggers.com/wp-content/uploads/2016/01/vent.txt") # from: http://www.wvgazettemail.com/
df <- data.frame(data)
textdata <- df[df$data, ]
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub("[[:digit:]]", "", textdata)
textdata = gsub("http\\w+", "", textdata)
textdata = gsub("[ \t]{2,}", "", textdata)
textdata = gsub("^\\s+|\\s+$", "", textdata)
try.error = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
textdata = sapply(textdata, try.error)
textdata = textdata[!is.na(textdata)]
names(textdata) = NULL
class_emo = classify_emotion(textdata, algorithm="bayes", prior=1.0)
emotion = class_emo[,7]
emotion[is.na(emotion)] = "unknown"
class_pol = classify_polarity(textdata, algorithm="bayes")
polarity = class_pol[,4]
sent_df = data.frame(text=textdata, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
class_emo = classify_emotion(textdata, algorithm="bayes", prior=1.0)
?stopwords
stopwords("german")
install.packages("Rcpp")
install.packages("Rcpp")
install.packages("Rcpp")
library(tm)
library(stringi)
library(proxy)
library(tm)
library(qdap)
install.packages("qdap")
library(qdapDictionaries)
library(dplyr)
# Data wrangling, pipe operator %>%().
library(RColorBrewer)
library(ggplot2)
library(scales)
library(Rgraphviz)
install.packages("Rgraphviz")
ord <- order(freq)
wf
p <- ggplot(subset(wf1, freq1>10), aes(word, freq))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
m <- as.matrix(dtm)
dim(m)
dtms <- removeSparseTerms(dtm, 0.1)
dim(dtms)
findFreqTerms(dtm, lowfreq=1000)
findFreqTerms(dtm, lowfreq=25)
findAssocs(dtm, "zika", corlimit=0.6)
findAssocs(dtm, "zika", corlimit=0.2)
findAssocs(dtm, "zika", corlimit=0.1)
findAssocs(dtm, "zika", corlimit=0)
findAssocs(dtm, "februar", corlimit=0.2)
plot(dtm,
terms=findFreqTerms(dtm, lowfreq=100)[1:50],
corThreshold=0.5)
install.packages("Rgraphviz")
source("https://bioconductor.org/biocLite.R")
biocLite("Rgraphviz")
library(Rgraphviz)
plot(dtm,
terms=findFreqTerms(dtm, lowfreq=100)[1:50],
corThreshold=0.5)
