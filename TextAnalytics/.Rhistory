articles[i] <- stri_flatten(readLines(stri_paste(wiki, titles[i])), col = " ")
}
i
stri_paste(wiki, titles[i])), col = " ")
stri_paste(wiki, titles[i])
wiki <- "http://de.wikipedia.org/wiki/"
titles <- c("Zika-Virus", "Influenza-A-Virus_H1N1", "Spanische_Grippe", "Influenzavirus",
"Vogelgrippe_H5N1", "Legionellose-Ausbruch_in_Warstein_2013", "Legionellose-Ausbruch_in_Jülich_2014")
articles <- character(length(titles))
for (i in 1:length(titles)) {
articles[i] <- stri_flatten(readLines(stri_paste(wiki, titles[i])), col = " ")
}
docs <- Corpus(VectorSource(articles))
docs2 <- tm_map(docs, function(x) stri_replace_all_regex(x, "<.+?>", " "))
docs3 <- tm_map(docs2, function(x) stri_replace_all_fixed(x, "\t", " "))
docs4 <- tm_map(docs3, PlainTextDocument)
docs5 <- tm_map(docs4, stripWhitespace)
docs6 <- tm_map(docs5, removeWords, stopwords("english"))
docs7 <- tm_map(docs6, removePunctuation)
docs8 <- tm_map(docs7, tolower)
length(docs8)
getwd()
setwd("TextAnalytics/")
save(docs8,file="data/Krankheiten_wiki.Rdata")
load("data/Krankheiten_wiki.Rdata")
docsTDM <- TermDocumentMatrix(docs8)
docsTDM <- TermDocumentMatrix(docs8)
docs8 <- tm_map(docs7, tolower)
docsTDM <- TermDocumentMatrix(docs8)
?TermDocumentMatrix
data("crude")
typeof(crude)
typeof(crude[[1]])
typeof(docs8)
docsTDM <- TermDocumentMatrix(docs8[[1]])
docsTDM <- TermDocumentMatrix(docs8)
crude
docs8
docs2
docs
articles
library(tm)
library(stringi)
library(proxy)
wiki <- "http://en.wikipedia.org/wiki/"
titles <- c("Integral", "Riemann_integral", "Riemann-Stieltjes_integral", "Derivative",
"Limit_of_a_sequence", "Edvard_Munch", "Vincent_van_Gogh", "Jan_Matejko",
"Lev_Tolstoj", "Franz_Kafka", "J._R._R._Tolkien")
articles <- character(length(titles))
for (i in 1:length(titles)) {
articles[i] <- stri_flatten(readLines(stri_paste(wiki, titles[i])), col = " ")
}
docs <- Corpus(VectorSource(articles))
docs <- Corpus(VectorSource(articles))
docs2 <- tm_map(docs, function(x) stri_replace_all_regex(x, "<.+?>", " "))
docs3 <- tm_map(docs2, function(x) stri_replace_all_fixed(x, "\t", " "))
docs4 <- tm_map(docs3, PlainTextDocument)
docs5 <- tm_map(docs4, stripWhitespace)
docs6 <- tm_map(docs5, removeWords, stopwords("english"))
docs7 <- tm_map(docs6, removePunctuation)
docs8 <- tm_map(docs7, tolower)
docsTDM <- TermDocumentMatrix(docs8)
docs8
docsdissim <- dissimilarity(docsTDM, method = "cosine")
library(tm)
library(stringi)
library(proxy)
docsTDM <- TermDocumentMatrix(docs8)
docsdissim <- dissimilarity(docsTDM, method = "cosine")
library(arules)
install.packages("arules")
library(arules)
docsTDM <- TermDocumentMatrix(docs8)
docsdissim <- dissimilarity(docsTDM, method = "cosine")
docs8 <- tm_map(docs8, PlainTextDocument)
docsTDM <- TermDocumentMatrix(docs8)
docsdissim <- dissimilarity(docsTDM, method = "cosine")
docsdissim <- tm::dissimilarity(docsTDM, method = "cosine")
docsdissim <- tm:::dissimilarity(docsTDM, method = "cosine")
docsdissim <- tm::dissimilarity(docsTDM, method = "cosine")
detach("package:arules", unload=TRUE)
docsdissim <- dissimilarity(docsTDM, method = "cosine")
library("tm", lib.loc="~/R/win-library/3.3")
docsdissim <- dissimilarity(docsTDM, method = "cosine")
docsdissim <- dissimilarity(docsTDM, method = "cosine")
docsdissim <- tm::dissimilarity(docsTDM, method = "cosine")
docsdissim <- tm:::dissimilarity(docsTDM, method = "cosine")
docsdissim <- proxy::dist(docsTDM, method = "cosine")
docsdissim <- proxy::dist(docsTDM)
?proxy::dist
start   = "http://www.iens.nl/restaurant/?q=&amp;amp;perPagina=20&amp;amp;pagina="
httploc = paste(start,i,sep="")
restaurants     = html(httploc)
recensieinfo    = html_text(html_nodes(restaurants,xpath='//div[@class="listerItem_score"]'))
restaurantLabel = html_nodes(restaurants,".listerItem")
restName        = html_text(html_nodes(reslabel2,".fontSerif"))
restAddress     = html_nodes(restarantLabel ,"div address")
Nreviews        = str_extract(str_extract(recensieinfo,pattern="[0-9]* recensies"), pattern = "[0-9]*")
averageScore    = str_extract(recensieinfo,pattern="[0-9].[0-9]")
# more statements
Needed <- c("tm", "SnowballCC", "RColorBrewer", "ggplot2", "wordcloud", "biclust", "cluster", "igraph", "fpc")
install.packages(Needed, dependencies=TRUE)
Needed <- c("tm", "SnowballCC", "RColorBrewer", "ggplot2", "wordcloud", "biclust", "cluster", "igraph", "fpc")
install.packages(Needed, dependencies=TRUE)
install.packages(Needed, dependencies = TRUE)
library(tm)
library(stringi)
library(proxy)
load("data/Krankheiten_wiki.Rdata")
(load("data/Krankheiten_wiki.Rdata"))
summary(docs8)
summary(Corpus(docs8))
summary(docs8)
docs8
docs <- tm_map(docs8, removePunctuation)
docs
inspect(docs8[3])
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("german"))
docs
inspect(docs8[3])
docs <- tm_map(docs, removeWords, c("document", "element"))
docs
inspect(docs8[3])
library(SnowballC)
docs <- tm_map(docs, stemDocument)
docs <- TermDocumentMatrix(docs)
docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
dtm
tdm <- TermDocumentMatrix(docs)
freq <- colSums(as.matrix(dtm))
length(freq)
dtms <- removeSparseTerms(dtm, 0.1)
inspect(dtms)
freq[head(ord)]
head(table(freq), 20)
freq <- colSums(as.matrix(dtms))
freq
library(ggplot2)
p <- ggplot(subset(wf, freq>50), aes(word, freq))
wf <- data.frame(word=names(freq), freq=freq)
library(ggplot2)
p <- ggplot(subset(wf, freq>50), aes(word, freq))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
freq <- colSums(as.matrix(dtms[1]))
freq <- colSums(as.matrix(dtms[[1]))
dtm <- DocumentTermMatrix(docs[1])
dtm
dtm2 <- DocumentTermMatrix(docs[2])
tdm2 <- TermDocumentMatrix(docs[2])
dtm1 <- DocumentTermMatrix(docs[1])
tdm1 <- TermDocumentMatrix(docs[1])
freq1 <- colSums(as.matrix(dtm1))
dtms1 <- removeSparseTerms(dtm1, 0.1)
dtms1 <- removeSparseTerms(dtm1, 0.1)
freq1 <- colSums(as.matrix(dtms1))
wf1 <- data.frame(word=names(freq1), freq=freq1)
p <- ggplot(subset(wf1, freq1>50), aes(word1, freq1))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
p <- ggplot(subset(wf1, freq1>50), aes(word, freq1))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
p <- ggplot(subset(wf1, freq1>50), aes(word, freq))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
install.packages("devtools")
require(devtools)
install_url("http://www.omegahat.org/Rstem/Rstem_0.4-1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.1.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz")
library("plyr")
library("ggplot2")
library("wordcloud")
library("RColorBrewer")
library("tm")
library("SnowballC")
data <- readLines("https://www.r-bloggers.com/wp-content/uploads/2016/01/vent.txt") # from: http://www.wvgazettemail.com/
df <- data.frame(data)
textdata <- df[df$data, ]
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub("[[:punct:]]", "", textdata)
textdata = gsub("[[:digit:]]", "", textdata)
textdata = gsub("http\\w+", "", textdata)
textdata = gsub("[ \t]{2,}", "", textdata)
textdata = gsub("^\\s+|\\s+$", "", textdata)
try.error = function(x)
{
y = NA
try_error = tryCatch(tolower(x), error=function(e) e)
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
textdata = sapply(textdata, try.error)
textdata = textdata[!is.na(textdata)]
names(textdata) = NULL
class_emo = classify_emotion(textdata, algorithm="bayes", prior=1.0)
emotion = class_emo[,7]
emotion[is.na(emotion)] = "unknown"
class_pol = classify_polarity(textdata, algorithm="bayes")
polarity = class_pol[,4]
sent_df = data.frame(text=textdata, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
class_emo = classify_emotion(textdata, algorithm="bayes", prior=1.0)
?stopwords
stopwords("german")
install.packages("Rcpp")
install.packages("Rcpp")
install.packages("Rcpp")
library(tm)
library(stringi)
library(proxy)
library(tm)
library(qdap)
install.packages("qdap")
library(qdapDictionaries)
library(dplyr)
# Data wrangling, pipe operator %>%().
library(RColorBrewer)
library(ggplot2)
library(scales)
library(Rgraphviz)
install.packages("Rgraphviz")
ord <- order(freq)
wf
p <- ggplot(subset(wf1, freq1>10), aes(word, freq))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
m <- as.matrix(dtm)
dim(m)
dtms <- removeSparseTerms(dtm, 0.1)
dim(dtms)
findFreqTerms(dtm, lowfreq=1000)
findFreqTerms(dtm, lowfreq=25)
findAssocs(dtm, "zika", corlimit=0.6)
findAssocs(dtm, "zika", corlimit=0.2)
findAssocs(dtm, "zika", corlimit=0.1)
findAssocs(dtm, "zika", corlimit=0)
findAssocs(dtm, "februar", corlimit=0.2)
plot(dtm,
terms=findFreqTerms(dtm, lowfreq=100)[1:50],
corThreshold=0.5)
install.packages("Rgraphviz")
source("https://bioconductor.org/biocLite.R")
biocLite("Rgraphviz")
library(Rgraphviz)
plot(dtm,
terms=findFreqTerms(dtm, lowfreq=100)[1:50],
corThreshold=0.5)
gsub("[A-Z]","-",str1)
str1 <- c("ABCDJ89877266HJZ")
gsub("[A-Z]","-",str1)
str2 <- "ahdsjdkAZZUSJ77328JJHiiis"
gsub("[:lower:]","[:upper:]",str2)
gsub("[:lower:]","-",str2)
library(tm)
library(stringi)
library(proxy)
(load("data/Krankheiten_wiki.Rdata"))
docs <- tm_map(docs8, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("german"))
docs <- tm_map(docs, removeWords, c("document", "element"))
library(SnowballC)
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, PlainTextDocument)
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)
dtm2 <- as.matrix(dtm)
frequency <- colSums(dtm2)
frequency <- sort(frequency, decreasing=TRUE)
mots=frequency[frequency>20]
s=dtm2[1,which(colnames(dtm2) %in% names(mots))]
for(i in 2:nrow(dtm2)) s=cbind(s,dtm2[i,which(colnames(dtm2) %in% names(mots))])
colnames(s)=titles
titles <- c("Zika-Virus", "Influenza-A-Virus_H1N1", "Spanische_Grippe", "Influenzavirus",
"Vogelgrippe_H5N1", "Legionellose-Ausbruch_in_Warstein_2013", "Legionellose-Ausbruch_in_Jülich_2014")
colnames(s)=titles
library(FactoMineR)
install.packages("FactoMineR")
library(FactoMineR)
install.packages("tibble")
library(FactoMineR)
PCA(s)
s0=s/apply(s,1,sd)
h <- hclust(dist(t(s0)), method = "ward")
plot(h, labels = titles, sub = "")
library(rpart)
fit <- rpart(Kyphosis ~ Age + Number + Start,
method="class", data=kyphosis)
head(kyphosis)
table(kyphosis$Kyphosis)
printcp(fit) # display the results
plotcp(fit) # visualize cross-validation results
summary(fit) # detailed summary of splits
plot(fit, uniform=TRUE,
main="Classification Tree for Kyphosis")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
# create attractive postscript plot of tree
post(fit, file = "c:/tree.ps",
title = "Classification Tree for Kyphosis")
# create attractive postscript plot of tree
post(fit, file = "c:/tree.ps",
title = "Classification Tree for Kyphosis")
library(twitteR)
install.packages("twitteR")
library(twitteR)
tweets <- userTimeline("RDataMining", n = 3200)
library(dplyr)
library(purrr)
install.packages("purrr")
library(twitteR)
install.packages("twitteR")
library(dplyr)
library(twitteR)
tweets <- userTimeline("RDataMining", n = 3200)
lapply(c('twitteR', 'dplyr', 'ggplot2', 'lubridate', 'network', 'sna', 'qdap', 'tm'),
library, character.only = TRUE)
install.packages("network")
install.packages("sna")
install.packages("qdap")
lapply(c('twitteR', 'dplyr', 'ggplot2', 'lubridate', 'network', 'sna', 'qdap', 'tm'),
library, character.only = TRUE)
INC <- runif(N)
N <- 1000
INC <- runif(N)
N <- 1000
INC <- runif(N)
SEX <- sample(c(1,2),N,replace=T)
t.test(INC[SEX==1],INC[SEX==2])
library(faraway)
install.packages("faraway")
library(faraway)
data(orings)
plot(damage/6 ~ temp, orings, xlim=c(0,100), ylim=c(0,1),
xlab="Temperatur", ylab="Unfall")
lmod <- lm(damage/6 ~ temp, orings)
abline(lmod, col=4); abline(h=0); abline(h=1)
summary(m<-lm ( am ~ PS + wt,mtcars))
summary(m<-lm ( am ~ PS + wt,data=mtcars))
mtcars
summary(m<-lm ( am ~ hp + wt,data=mtcars))
predict(m,data.frame(PS=65,wt=2))
predict(m,data.frame(hp=65,wt=2))
predict(m,data.frame(hp=180,wt=2))
library(solaR)
install.packages("solaR")
summary(mod1<-lm(sqrt(Species)~Area+Elevation+Nearest,gala))
library(nnet)
multinom(formula = low ~ ., data = bwt)
example(birthwt)
library(MASS)
example(birthwt)
head(bwt)
summary(bwt)
multinom(formula = low ~ ., data = bwt)
head(nes96[,c(8:10)])
inca <- c(1.5,4,6,8,9.5,10.5,11.5,12.5,13.5,14.5,16,18.5,
21,23.5,27.5,32.5,37.5,42.5,47.5,55,67.5,82.5,97.5,115)
nincome <- inca[unclass(nes96$income)]
summary(nincome)
barplot(table(nes96$educ),col="chocolate1")
matplot(prop.table(table(nes96$educ,sPID),1),type="l",
xlab="Education",ylab="Proportion",lty=c(1,2,5))
head(nes96[,c(8:10)])
data(nes96)
sPID <- nes96$PID
summary(sPID)
levels(sPID) <- c("Democrat","Democrat","Independent",
"Independent", "Independent","Republican","Republican")
summary(sPID)
inca <- c(1.5,4,6,8,9.5,10.5,11.5,12.5,13.5,14.5,16,18.5,
21,23.5,27.5,32.5,37.5,42.5,47.5,55,67.5,82.5,97.5,115)
nincome <- inca[unclass(nes96$income)]
summary(nincome)
barplot(table(nes96$educ),col="chocolate1")
matplot(prop.table(table(nes96$educ,sPID),1),type="l",
xlab="Education",ylab="Proportion",lty=c(1,2,5))
library(nnet)
mmod <- multinom(sPID ~ age + educ + nincome, nes96)
predict(mmodi,data.frame(nincome=il),type="probs")
mmodi <- step(mmod)
predict(mmodi,data.frame(nincome=il),type="probs")
predict(mmodi,data.frame(nincome=il),type="probs")
summary(mmodi)
predict(mmodi,data.frame(nincome=0),type="probs")
il <- 5
predict(mmodi,data.frame(nincome=il),type="probs")
summary(mmodi)
library(polr)
install.packages("polr")
library(MASS)
?polr
pomod <- polr(sPID ~ age + educ + nincome, nes96)
c(deviance(pomod), pomod$edf)
data("BankWages", package="AER")
install.packages("AER")
data("BankWages", package="AER")
summary(BankWages)
library(gplots)
install.packages("gplots")
library(gplots)
balloonplot(BankWages$job, BankWages$education,
BankWages$gender, xlab="job", ylab ="education")
library(faraway)
data(bliss)
bliss
data(gala)
gala <- gala[,-2]
mod1 <- lm(Species ~ . , gala)
data(dicentric)
round(xtabs(ca/cells ~ doseamt + doserate,dicentric),2)
rmod <- glm(ca ~ offset(log(cells))+log(doserate)*dosef,
family=poisson,dicentric)
summary(rmod)
rmod <- glm(ca ~ offset(log(cells))+log(doserate)*doseamt,
family=poisson,dicentric)
summary(rmod)
library(vcd)
install.packages("vcd")
library(vcd)
data(nes96)
sPID <- nes96$PID
levels(sPID) <- c("Democrat","Democrat","Independent",
"Independent","Independent","Republican","Republican")
Age <- nes96$age
cd_plot(sPID ~ Age)
motorins <- read.table("http://www.statsci.org/data/general/motorins.txt",header=T)
head(motorins)
attach(motorins)
library(vcd)
distplot(Claims)
assoc(table(Bonus,Make),shade=T,main="")
model1 <- glm(y ~ S + RK2 + RK3 + RK4 + RK5 + RK6 + RK7 + SFK
+ FK1 + FK2 + FK3 + FK4 + FK5 + FK6 + FK7 + FK8 +
offset(log(KG)), family = poisson)
head(motorins)
x <- c(3,5,8,7,9,12,17,10,5,9,14,22)
y <- c(17,25,9,21,12,14,10,12,14,10,16,12,19,14,28)
t.test(x, y, alternative="two.sided", var.equal=F,
paired=F, mu=0, conf.level=0.99)
WiWi    <- c(37097 ,45617, 41115 ,32510, 35940, 38247, 33352,
42367, 29564 ,34896)
Sozi    <- c(46109, 28399, 42363 ,32928, 36893, 41527, 41074,
27341, 36904 ,36247)
Math    <- c(41527, 36891 ,35220, 43529, 34941, 41565, 52383,
36348, 37014 ,37897)
Stat    <- c("N", "N", "N", "J", "J", "N", "J", "N", "J", "J", "N", "J", "N", "J", "J", "N", "N", "J", "J",
"J", "N", "J", "J", "N", "J", "N", "N", "J", "J", "J")
Studis <- c(WiWi, Sozi ,Math)
Index <- as.factor(rep(1:3,c(10,10,10)))
levels(Index) <- c("WiWi", "Sozi", "Math")
Data <- data.frame(Index=factor(Index),Studis,Stat)
boxplot(Studis ~ Index, col=c(2,3,4)); abline(h=mean(Studis), lty=2)
lines(c(0.55,1.45), c(mean(WiWi),mean(WiWi)), type="o")
lines(c(1.55,2.45), c(mean(Sozi),mean(Sozi)), type="o")
lines(c(2.55,3.45), c(mean(Math),mean(Math)), type="o")
summary(kont1)
sex <- rep(1,100)
sex[sample(1:100,50)] <- 2
smog <- rep(1,100)
smog[sample(which(sex==1),20)]<- 2
smog[sample(which(sex==2),24)]<- 2
kont <- cbind(smog,sex)
kont1 <- table(smog,sex)
kont2<-ftable(sex~smog,data=kont)
kont2
chi <- chisq.test(kont1)
chi$expected
mu_e <- kont1
mu_e[1,1] <- prop.table(colSums(kont1))[1]*prop.table(rowSums(kont1))[1]
mu_e[1,2] <- prop.table(colSums(kont1))[1]*prop.table(rowSums(kont1))[2]
mu_e[2,1] <- prop.table(colSums(kont1))[2]*prop.table(rowSums(kont1))[1]
mu_e[2,2] <- prop.table(colSums(kont1))[2]*prop.table(rowSums(kont1))[2]
sum(((prop.table(kont1) - mu_e)^2) /mu_e)
library(FactoMineR)
install.packages("FactoMineR")
install.packages("FactoMineR")
library(e1071)
data(iris)
attach(iris)
model <- svm(Species ~ ., data = iris)
model
install.packages("pdftools")
library(devtools)
install_github("ropensci/tabulizer")
library(tabulizer)
f <- system.file("examples", "data.pdf", package = "tabulizer")
f
library(knitr)
kable(dataframe(a=1:4,b=4:1))
kable(data.frame(a=1:4,b=4:1))
library(htmlTable)
tab1c <- data.frame(a=1:4,b=4:1)
kable(tab1c)
library(xtable)
?xtable
?kable
930+8
930+800
930+830
